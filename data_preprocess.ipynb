{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserItemRatingDataset(Dataset):\n",
    "    def __init__(self, user, item, target) -> None:\n",
    "        super().__init__()\n",
    "        self.user = user\n",
    "        self.item = item\n",
    "        self.target = target\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.user[index], self.item[index], self.target[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.user.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self, ratings):\n",
    "        self.ratings = ratings\n",
    "        self.preprocess_ratings = self._binarize(ratings)\n",
    "        self.user_pool = set(self.ratings['userId'].unique())\n",
    "        self.item_pool = set(self.ratings['itemId'].unique())\n",
    "        self.negatives = self._negative(self.ratings)\n",
    "        self.train_ratings, self.test_ratings = self._split(self.preprocess_ratings)\n",
    "\n",
    "    # For explicit feedback\n",
    "    def _binarize(self, ratings):\n",
    "        ratings = deepcopy(ratings)\n",
    "        ratings['rating'][ratings['rating'] > 0] = 1.0\n",
    "        return ratings\n",
    "    \n",
    "    def _negative(self, ratings):\n",
    "        interact_status = ratings.groupby('userId')['itemId'].apply(set).reset_index().rename(\n",
    "            columns={'itemId': 'interacted_items'}\n",
    "        )\n",
    "        interact_status['negative_items'] = interact_status['interacted_items'].apply(lambda x: self.item_pool - x)\n",
    "        interact_status['negative_samples'] = interact_status['negative_items'].apply(lambda x: random.sample(x, 99))\n",
    "        return interact_status[['userId', 'negative_items', 'negative_samples']]\n",
    "    \n",
    "    def _split(self, ratings):\n",
    "        ratings['rank_latest'] = ratings.groupby('userId')['timestamp'].rank(method='first', ascending=False)\n",
    "        test = ratings[ratings['rank_latest'] == 1]\n",
    "        train = ratings[ratings['rank_latest'] > 1]\n",
    "        assert train['userId'].nunique() == test['userId'].nunique()\n",
    "        return train[['userId', 'itemId', 'rating']], test[['userId', 'itemId', 'rating']]\n",
    "    \n",
    "    def get_train_loader(self, num_negatives, batch_size):\n",
    "        users, items, ratings = [], [], []\n",
    "        train_ratings = pd.merge(self.train_ratings, self.negatives[['userId', 'negative_items']], on='userId')\n",
    "        train_ratings['negatives'] = train_ratings['negative_items'].apply(lambda x: random.sample(x, num_negatives))\n",
    "        for row in train_ratings.itertuples():\n",
    "            users.append(int(row.userId))\n",
    "            items.append(int(row.itemId))\n",
    "            ratings.append(float(row.rating))\n",
    "            for i in range(num_negatives):\n",
    "                users.append(int(row.userId))\n",
    "                items.append(int(row.negatives[i]))\n",
    "                ratings.append(float(0)) # negative samples get 0 rating\n",
    "        \n",
    "        dataset = UserItemRatingDataset(user = torch.LongTensor(users),\n",
    "                                        item = torch.LongTensor(items), \n",
    "                                        target_tensor = torch.FloatTensor(ratings))\n",
    "        \n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    @property\n",
    "    def get_evaluate_data(self):\n",
    "        test_ratings = pd.merge(self.test_ratings, self.negatives[['userId', 'negative_samples']], on='userId')\n",
    "        test_users, test_items, negative_users, negative_items = [], [], [], []\n",
    "        for row in test_ratings.itertuples():\n",
    "            test_users.append(int(row.userId))\n",
    "            test_items.append(int(row.itemId))\n",
    "            for i in range(len(row.negative_samples)):\n",
    "                negative_users.append(int(row.userId))\n",
    "                negative_items.append(int(row.negative_samples[i]))\n",
    "        return [torch.LongTensor(test_users), torch.LongTensor(test_items), torch.LongTensor(negative_users), torch.LongTensor(negative_items)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ml1m_dir = 'old/movielens/ml-1m/ml-1m/ratings.dat'\n",
    "ml1m_rating = pd.read_csv(ml1m_dir, sep='::', header=None, names=['uid', 'mid', 'rating', 'timestamp'], engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>mid</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid   mid  rating  timestamp\n",
       "0    1  1193       5  978300760\n",
       "1    1   661       3  978302109\n",
       "2    1   914       3  978301968\n",
       "3    1  3408       4  978300275\n",
       "4    1  2355       5  978824291"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml1m_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = ml1m_rating[['uid']].drop_duplicates().reindex()\n",
    "user_id['userId'] = np.arange(len(user_id))\n",
    "ml1m_rating = pd.merge(ml1m_rating, user_id, on=['uid'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id = ml1m_rating[['mid']].drop_duplicates()\n",
    "item_id['itemId'] = np.arange(len(item_id))\n",
    "ml1m_rating = pd.merge(ml1m_rating, item_id, on=['mid'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml1m_rating = ml1m_rating[['userId', 'itemId', 'rating', 'timestamp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of userId is [0, 6039]\n",
      "Range of itemId is [0, 3705]\n"
     ]
    }
   ],
   "source": [
    "print('Range of userId is [{}, {}]'.format(ml1m_rating.userId.min(), ml1m_rating.userId.max()))\n",
    "print('Range of itemId is [{}, {}]'.format(ml1m_rating.itemId.min(), ml1m_rating.itemId.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\25540\\AppData\\Local\\Temp\\ipykernel_33836\\2376750757.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ratings['rating'][ratings['rating'] > 0] = 1.0\n",
      "C:\\Users\\25540\\AppData\\Local\\Temp\\ipykernel_33836\\2376750757.py:21: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  interact_status['negative_samples'] = interact_status['negative_items'].apply(lambda x: random.sample(x, 99))\n"
     ]
    }
   ],
   "source": [
    "generator = Generator(ml1m_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_data = generator.get_evaluate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,    0,    0,  ..., 6039, 6039, 6039])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_data[2].view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "neumf_config = {'alias': 'neumf_factor8neg4',\n",
    "                'num_epoch': 200,\n",
    "                'batch_size': 1024,\n",
    "                'optimizer': 'adam',\n",
    "                'adam_lr': 1e-3,\n",
    "                'num_users': 6040,\n",
    "                'num_items': 3706,\n",
    "                'latent_dim_mf': 8,\n",
    "                'latent_dim_mlp': 8,\n",
    "                'num_negative': 4,\n",
    "                'layers': [16, 64, 32, 16, 8],  # layers[0] is the concat of latent user vector & latent item vector\n",
    "                'l2_regularization': 0.0000001,\n",
    "                'weight_init_gaussian': True,\n",
    "                'use_cuda': True,\n",
    "                'device_id': 0,\n",
    "                'pretrain': False,\n",
    "                'pretrain_mf': 'checkpoints/{}'.format('gmf_factor8neg4_Epoch100_HR0.6391_NDCG0.2852.model'),\n",
    "                'pretrain_mlp': 'checkpoints/{}'.format('mlp_factor8neg4_Epoch100_HR0.5606_NDCG0.2463.model'),\n",
    "                'model_dir': 'checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model'\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_config = {'alias': 'mlp_factor8neg4_bz256_166432168_pretrain_reg_0.0000001',\n",
    "              'num_epoch': 200,\n",
    "              'batch_size': 256,  # 1024,\n",
    "              'optimizer': 'adam',\n",
    "              'adam_lr': 1e-3,\n",
    "              'num_users': 6040,\n",
    "              'num_items': 3706,\n",
    "              'latent_dim': 8,\n",
    "              'num_negative': 4,\n",
    "              'layers': [16, 64, 32, 16, 8],  # layers[0] is the concat of latent user vector & latent item vector\n",
    "              'l2_regularization': 0.0000001,  # MLP model is sensitive to hyper params\n",
    "              'weight_init_gaussian': True,\n",
    "              'use_cuda': True,\n",
    "              'device_id': 0,\n",
    "              'pretrain': False,\n",
    "              'pretrain_mf': 'checkpoints/{}'.format('gmf_factor8neg4_Epoch100_HR0.6391_NDCG0.2852.model'),\n",
    "              'model_dir': 'checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmf_config = {'alias': 'gmf_factor8neg4-implict',\n",
    "              'num_epoch': 200,\n",
    "              'batch_size': 1024,\n",
    "              # 'optimizer': 'sgd',\n",
    "              # 'sgd_lr': 1e-3,\n",
    "              # 'sgd_momentum': 0.9,\n",
    "              # 'optimizer': 'rmsprop',\n",
    "              # 'rmsprop_lr': 1e-3,\n",
    "              # 'rmsprop_alpha': 0.99,\n",
    "              # 'rmsprop_momentum': 0,\n",
    "              'optimizer': 'adam',\n",
    "              'adam_lr': 1e-3,\n",
    "              'num_users': 6040,\n",
    "              'num_items': 3706,\n",
    "              'latent_dim': 8,\n",
    "              'num_negative': 4,\n",
    "              'l2_regularization': 0,  # 0.01\n",
    "              'weight_init_gaussian': True,\n",
    "              'use_cuda': True,\n",
    "              'device_id': 0,\n",
    "              'model_dir': 'checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuMF(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      42.0\n",
       "1      23.0\n",
       "2      28.0\n",
       "3      47.0\n",
       "4       4.0\n",
       "5      15.0\n",
       "6      26.0\n",
       "7      45.0\n",
       "8      16.0\n",
       "9      41.0\n",
       "10      7.0\n",
       "11     35.0\n",
       "12     14.0\n",
       "13     22.0\n",
       "14     33.0\n",
       "15     19.0\n",
       "16      8.0\n",
       "17     30.0\n",
       "18     36.0\n",
       "19     27.0\n",
       "20     17.0\n",
       "21     43.0\n",
       "22     50.0\n",
       "23     12.0\n",
       "24     49.0\n",
       "25      1.0\n",
       "26     29.0\n",
       "27     51.0\n",
       "28     13.0\n",
       "29      9.0\n",
       "30      5.0\n",
       "31     53.0\n",
       "32      2.0\n",
       "33     10.0\n",
       "34      3.0\n",
       "35      6.0\n",
       "36     48.0\n",
       "37     52.0\n",
       "38     24.0\n",
       "39     31.0\n",
       "40     11.0\n",
       "41     38.0\n",
       "42     34.0\n",
       "43     39.0\n",
       "44     44.0\n",
       "45     32.0\n",
       "46     18.0\n",
       "47     46.0\n",
       "48     37.0\n",
       "49     21.0\n",
       "50     20.0\n",
       "51     40.0\n",
       "52     25.0\n",
       "53    102.0\n",
       "54     80.0\n",
       "Name: timestamp, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml1m_rating.groupby(['userId'])['timestamp'].rank(method='first', ascending=False)[:55]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
