{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47f6479e",
   "metadata": {},
   "source": [
    "# STA326 Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88b1309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "\n",
    "import scipy.sparse as sp\n",
    "import math\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53b010aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3788575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d507bc2",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ffaa23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all(data_name):\n",
    "    \"\"\" We load all the three file here to save time in each epoch. \"\"\"\n",
    "    train_rating = './Data/{}.train.rating'.format(data_name)\n",
    "    train_data = pd.read_csv(\n",
    "        train_rating, \n",
    "        sep='\\t', header=None, names=['user', 'item'], \n",
    "        usecols=[0, 1], dtype={0: np.int32, 1: np.int32})\n",
    "\n",
    "    user_num = train_data['user'].max() + 1\n",
    "    item_num = train_data['item'].max() + 1\n",
    "\n",
    "    train_data = train_data.values.tolist()\n",
    "\n",
    "    # load ratings as a dok matrix\n",
    "    train_mat = sp.dok_matrix((user_num, item_num), dtype=np.float32)\n",
    "    for x in train_data:\n",
    "        train_mat[x[0], x[1]] = 1.0\n",
    "\n",
    "    test_negative = './Data/{}.test.negative'.format(data_name)\n",
    "    test_data = []\n",
    "    with open(test_negative, 'r') as fd:\n",
    "        line = fd.readline()\n",
    "        while line != None and line != '':\n",
    "            arr = line.split('\\t')\n",
    "            u = eval(arr[0])[0]\n",
    "            test_data.append([u, eval(arr[0])[1]])\n",
    "            for i in arr[1:]:\n",
    "                test_data.append([u, int(i)])\n",
    "            line = fd.readline()\n",
    "    return train_data, test_data, user_num, item_num, train_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1157ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCFData(Dataset):\n",
    "    def __init__(self, features, num_item, train_mat=None, num_ng=0, is_training=None):\n",
    "        super(NCFData, self).__init__()\n",
    "        \"\"\" Note that the labels are only useful when training, we thus \n",
    "            add them in the ng_sample() function.\n",
    "        \"\"\"\n",
    "        self.features_ps = features\n",
    "        self.num_item = num_item\n",
    "        self.train_mat = train_mat\n",
    "        self.num_ng = num_ng\n",
    "        self.is_training = is_training\n",
    "        self.labels = [0 for _ in range(len(features))]\n",
    "        \n",
    "        if self.is_training:\n",
    "            self.ng_sample()\n",
    "\n",
    "    def ng_sample(self):\n",
    "#         assert self.is_training, 'no need to sampling when testing'\n",
    "\n",
    "        self.features_ng = []\n",
    "        for x in self.features_ps:\n",
    "            u = x[0]\n",
    "            for t in range(self.num_ng):\n",
    "                j = np.random.randint(self.num_item)\n",
    "                while (u, j) in self.train_mat:\n",
    "                    j = np.random.randint(self.num_item)\n",
    "                self.features_ng.append([u, j])\n",
    "\n",
    "        labels_ps = [1 for _ in range(len(self.features_ps))]\n",
    "        labels_ng = [0 for _ in range(len(self.features_ng))]\n",
    "\n",
    "        self.features_fill = self.features_ps + self.features_ng\n",
    "        self.labels_fill = labels_ps + labels_ng\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.num_ng + 1) * len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = self.features_fill if self.is_training \\\n",
    "                    else self.features_ps\n",
    "        labels = self.labels_fill if self.is_training \\\n",
    "                    else self.labels\n",
    "\n",
    "        user = features[idx][0]\n",
    "        item = features[idx][1]\n",
    "        label = labels[idx]\n",
    "        return user, item ,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f850d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(data_name, batch_size, test_num_ng):\n",
    "#     data_name = 'ml-1m'\n",
    "#     batch_size = 256\n",
    "#     test_num_ng = 99\n",
    "\n",
    "    train_data, test_data, user_num ,item_num, train_mat = load_all(data_name)\n",
    "\n",
    "    # construct the train and test datasets\n",
    "    train_dataset = NCFData(train_data, item_num, train_mat, 4, True)\n",
    "    test_dataset = NCFData(test_data, item_num, train_mat, 0, False)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset,batch_size=test_num_ng+1, shuffle=False, num_workers=0)\n",
    "    return user_num,item_num,train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012c29ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "975320e7",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4ea10d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit(gt_item, pred_items):\n",
    "    if gt_item in pred_items:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def ndcg(gt_item, pred_items):\n",
    "    if gt_item in pred_items:\n",
    "        index = pred_items.index(gt_item)\n",
    "        return np.reciprocal(np.log2(index+2))\n",
    "    return 0\n",
    "\n",
    "def metrics(model, test_loader, top_k):\n",
    "    HR, NDCG = [], []\n",
    "\n",
    "    for user, item, label in test_loader:\n",
    "        user = user.to(device)\n",
    "        item = item.to(device)\n",
    "\n",
    "        predictions = model(user, item)\n",
    "        _, indices = torch.topk(predictions, top_k)\n",
    "        recommends = torch.take(item, indices).cpu().numpy().tolist()\n",
    "\n",
    "        gt_item = item[0].item()\n",
    "        HR.append(hit(gt_item, recommends))\n",
    "        NDCG.append(ndcg(gt_item, recommends))\n",
    "\n",
    "    return np.mean(HR), np.mean(NDCG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451f3742",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a711bc5a",
   "metadata": {},
   "source": [
    "GMF, MLP and NeuMF model are written in one Module class `NCF`.\n",
    "* GMF can be implemented using `NCF(user_num, item_num, factor_num, 0, 0.0, 'GMF', None, None)`.\n",
    "* MLP-i can be implemented using `NCF(user_num, item_num, factor_num, i, 0.0, 'MLP', None, None)`, where i represents the number of hidden layers.\n",
    "* NeuMF with pre-training can be implemented using `NCF(user_num, item_num, factor_num, i, 0.0, 'NeuMF-pre', GMF_model, MLP_model)`, where  GMF_model and MLP_model represent pre trained GMF and MLP, respectively, and i represents the number of hidden layers of MLP_model.\n",
    "* NeuMF that are trained from scratch can be implemented using `NCF(user_num, item_num, factor_num, i, 'NeuMF', None, None, None)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31b56131",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    def __init__(self, user_num, item_num, factor_num, num_layers,dropout, model, GMF_model=None, MLP_model=None):\n",
    "        super(NCF, self).__init__()\n",
    "        \"\"\"\n",
    "        user_num: number of users;\n",
    "        item_num: number of items;\n",
    "        factor_num: number of predictive factors;\n",
    "        num_layers: the number of layers in MLP model;\n",
    "        dropout: dropout rate between fully connected layers;\n",
    "        model: 'MLP', 'GMF', 'NeuMF-end', and 'NeuMF-pre';\n",
    "        GMF_model: pre-trained GMF weights;\n",
    "        MLP_model: pre-trained MLP weights.\n",
    "        \"\"\"        \n",
    "        self.dropout = dropout\n",
    "        self.model = model\n",
    "        self.GMF_model = GMF_model\n",
    "        self.MLP_model = MLP_model\n",
    "\n",
    "        # Embedding layers for GMF and MLP\n",
    "        self.embed_user_GMF = nn.Embedding(user_num, factor_num)\n",
    "        self.embed_item_GMF = nn.Embedding(item_num, factor_num)\n",
    "        self.embed_user_MLP = nn.Embedding(user_num, int(factor_num * (2 ** (num_layers - 1))))\n",
    "        self.embed_item_MLP = nn.Embedding(item_num, int(factor_num * (2 ** (num_layers - 1))))\n",
    "\n",
    "        # MLP layers\n",
    "        MLP_modules = []\n",
    "        for i in range(num_layers):\n",
    "            input_size = factor_num * (2 ** (num_layers - i))\n",
    "            MLP_modules.append(nn.Dropout(p=self.dropout))\n",
    "            MLP_modules.append(nn.Linear(input_size, input_size // 2))\n",
    "            MLP_modules.append(nn.ReLU())\n",
    "        self.MLP_layers = nn.Sequential(*MLP_modules)\n",
    "\n",
    "        # Prediction layer\n",
    "        if self.model in ['MLP', 'GMF']:\n",
    "            predict_size = factor_num \n",
    "        else:\n",
    "            predict_size = factor_num * 2\n",
    "        self.predict_layer = nn.Linear(predict_size, 1)\n",
    "\n",
    "        self._init_weight_()\n",
    "        \n",
    "    def _init_weight_(self):\n",
    "        \"\"\" We leave the weights initialization here. \"\"\"\n",
    "        if not self.model == 'NeuMF-pre':\n",
    "            nn.init.normal_(self.embed_user_GMF.weight, std=0.01)\n",
    "            nn.init.normal_(self.embed_user_MLP.weight, std=0.01)\n",
    "            nn.init.normal_(self.embed_item_GMF.weight, std=0.01)\n",
    "            nn.init.normal_(self.embed_item_MLP.weight, std=0.01)\n",
    "\n",
    "            for m in self.MLP_layers:\n",
    "                if isinstance(m, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.kaiming_uniform_(self.predict_layer.weight, a=1, nonlinearity='sigmoid')\n",
    "\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "        else:\n",
    "            # embedding layers\n",
    "            self.embed_user_GMF.weight.data.copy_(\n",
    "                            self.GMF_model.embed_user_GMF.weight)\n",
    "            self.embed_item_GMF.weight.data.copy_(\n",
    "                            self.GMF_model.embed_item_GMF.weight)\n",
    "            self.embed_user_MLP.weight.data.copy_(\n",
    "                            self.MLP_model.embed_user_MLP.weight)\n",
    "            self.embed_item_MLP.weight.data.copy_(\n",
    "                            self.MLP_model.embed_item_MLP.weight)\n",
    "\n",
    "            # mlp layers\n",
    "            for (m1, m2) in zip(\n",
    "                self.MLP_layers, self.MLP_model.MLP_layers):\n",
    "                if isinstance(m1, nn.Linear) and isinstance(m2, nn.Linear):\n",
    "                    m1.weight.data.copy_(m2.weight)\n",
    "                    m1.bias.data.copy_(m2.bias)\n",
    "\n",
    "            # predict layers\n",
    "            predict_weight = torch.cat([\n",
    "                self.GMF_model.predict_layer.weight, \n",
    "                self.MLP_model.predict_layer.weight], dim=1)\n",
    "            precit_bias = self.GMF_model.predict_layer.bias + \\\n",
    "                        self.MLP_model.predict_layer.bias\n",
    "\n",
    "            self.predict_layer.weight.data.copy_(0.5 * predict_weight)\n",
    "            self.predict_layer.bias.data.copy_(0.5 * precit_bias)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        if not self.model == 'MLP':\n",
    "            embed_user_GMF = self.embed_user_GMF(user)\n",
    "            embed_item_GMF = self.embed_item_GMF(item)\n",
    "            output_GMF = embed_user_GMF * embed_item_GMF\n",
    "        if not self.model == 'GMF':\n",
    "            embed_user_MLP = self.embed_user_MLP(user)\n",
    "            embed_item_MLP = self.embed_item_MLP(item)\n",
    "            interaction = torch.cat((embed_user_MLP, embed_item_MLP), -1)\n",
    "            output_MLP = self.MLP_layers(interaction)\n",
    "\n",
    "        if self.model == 'GMF':\n",
    "            concat = output_GMF\n",
    "        elif self.model == 'MLP':\n",
    "            concat = output_MLP\n",
    "        else:\n",
    "            concat = torch.cat((output_GMF, output_MLP), -1)\n",
    "            \n",
    "        prediction = self.predict_layer(concat)\n",
    "        prediction = torch.sigmoid(prediction)\n",
    "        return prediction.view(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0b3b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5986112",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cff73c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, train_loader, test_loader, NUM_EPOCHS, optimizer_name, lr, data_name, model_name, csv_name): \n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "        \n",
    "    loss_function = nn.BCEWithLogitsLoss()\n",
    "    top_k = 10\n",
    "    \n",
    "    # Create a CSV file if it does not exist.\n",
    "    csv_file_path = f'./Output/{csv_name}.csv'\n",
    "    file_exists = os.path.exists(csv_file_path)\n",
    "    if not file_exists:\n",
    "        with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile)\n",
    "            header = ['epoch', 'HR', 'NDCG', 'data_name', 'model_name']\n",
    "            csvwriter.writerow(header)\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "\n",
    "        for user, item, label in train_loader:\n",
    "            user = user.to(device)\n",
    "            item = item.to(device)\n",
    "            label = label.float().to(device)\n",
    "\n",
    "            prediction = model(user, item)\n",
    "            loss = loss_function(prediction, label)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        \n",
    "        HR, NDCG = metrics(model, test_loader, top_k)\n",
    "        \n",
    "        # Write data to csv file.\n",
    "        with open(csv_file_path, 'a', newline='') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile)\n",
    "            row = [epoch+1, HR, NDCG, data_name, model_name]\n",
    "            csvwriter.writerow(row)\n",
    "        \n",
    "        # Save model data every five epochs.\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            state = {\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'HR': HR,\n",
    "                    'NDCG': NDCG,\n",
    "                    'top_k': top_k,\n",
    "                    'epoch': (epoch+1),\n",
    "            }\n",
    "            save_dir = './Model'\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.mkdir(save_dir)\n",
    "            model_path = osp.join(save_dir, \"{}_{}_{}.pth\".format(model_name ,data_name , epoch+1))\n",
    "\n",
    "            torch.save(state, model_path)\n",
    "            \n",
    "            # Output information every five epochs.\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(\"The time elapse of epoch {:d} for model {} and data {}\".format(epoch+1,model_name, data_name) + \" is: \" + \n",
    "                    time.strftime(\"%H: %M: %S\", time.gmtime(elapsed_time)))\n",
    "            print(\"HR: {:.3f}\\tNDCG: {:.3f}\".format(np.mean(HR), np.mean(NDCG)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78722700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2686794",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4c94994",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "factor_num = 8\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27252613",
   "metadata": {},
   "source": [
    "Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f393e1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The time elapse of epoch 5 for model gmf and data ml-1m is: 00: 00: 35\n",
      "HR: 0.620\tNDCG: 0.354\n",
      "The time elapse of epoch 10 for model gmf and data ml-1m is: 00: 00: 34\n",
      "HR: 0.636\tNDCG: 0.364\n",
      "The time elapse of epoch 5 for model neumf_pre and data ml-1m is: 00: 00: 35\n",
      "HR: 0.662\tNDCG: 0.386\n",
      "The time elapse of epoch 10 for model neumf_pre and data ml-1m is: 00: 00: 34\n",
      "HR: 0.662\tNDCG: 0.386\n",
      "The time elapse of epoch 5 for model gmf and data pinterest-20 is: 00: 01: 06\n",
      "HR: 0.845\tNDCG: 0.516\n",
      "The time elapse of epoch 10 for model gmf and data pinterest-20 is: 00: 01: 08\n",
      "HR: 0.848\tNDCG: 0.521\n",
      "The time elapse of epoch 5 for model neumf_pre and data pinterest-20 is: 00: 01: 35\n",
      "HR: 0.862\tNDCG: 0.535\n",
      "The time elapse of epoch 10 for model neumf_pre and data pinterest-20 is: 00: 01: 37\n",
      "HR: 0.861\tNDCG: 0.535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for data_name in ['ml-1m', 'pinterest-20']:\n",
    "    user_num, item_num, train_loader, test_loader = loader(data_name, batch_size=batch_size, test_num_ng=99)\n",
    "    \n",
    "    for model_name in ['gmf','neumf_pre']:\n",
    "        optimizer_name = 'adam'\n",
    "        lr = 0.001\n",
    "        if model_name=='gmf':\n",
    "            model = NCF(user_num, item_num, factor_num, 0, 0.0, 'GMF', None, None)\n",
    "        else:\n",
    "            model_GMF = NCF(user_num, item_num, factor_num, 0, 0.0, 'GMF', None, None)\n",
    "            model_GMF.to(device)\n",
    "            checkpoint_GMF = torch.load('Model/gmf_pinterest-20_10.pth')\n",
    "            model_GMF.load_state_dict(checkpoint_GMF['state_dict'])\n",
    "\n",
    "            model_MLP = NCF(user_num, item_num, factor_num, 3, 0.0, 'MLP', None, None)\n",
    "            model_MLP.to(device)\n",
    "            checkpoint_MLP = torch.load('Model/mlp_3_pinterest-20_10.pth')\n",
    "            model_MLP.load_state_dict(checkpoint_MLP['state_dict'])\n",
    "            \n",
    "            model = NCF(user_num, item_num, factor_num, 3, 0.0, 'NeuMF-pre',model_GMF,model_MLP)\n",
    "            \n",
    "            optimizer_name = 'sgd'\n",
    "        model.to(device)\n",
    "        \n",
    "        training(model, train_loader, test_loader, NUM_EPOCHS, optimizer_name, lr, data_name, model_name, 'ncf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a11a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7317c618",
   "metadata": {},
   "source": [
    "MLP with hidden layers ranging from 0 to 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0bcfb0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MLP with hidden layers ranging from 0 to 4 on data_name\n",
    "\n",
    "def MLP_layers(data_name, NUM_EPOCHS, optimizer_name, lr):\n",
    "    user_num, item_num, train_loader, test_loader = loader(data_name, batch_size=batch_size, test_num_ng=99)\n",
    "    for i in range(5):       \n",
    "        model = NCF(user_num, item_num, 8, i, 0.0, 'MLP', None, None)\n",
    "        model.to(device)\n",
    "        training(model, train_loader, test_loader, NUM_EPOCHS, optimizer_name, lr, data_name, f'mlp_{i}', 'mlp', layers_num=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84a827a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The time elapse of epoch 5 for model mlp_0 and data ml-1m is: 00: 00: 38\n",
      "HR: 0.453\tNDCG: 0.252\n",
      "The time elapse of epoch 10 for model mlp_0 and data ml-1m is: 00: 00: 37\n",
      "HR: 0.453\tNDCG: 0.253\n",
      "The time elapse of epoch 5 for model mlp_1 and data ml-1m is: 00: 00: 38\n",
      "HR: 0.558\tNDCG: 0.313\n",
      "The time elapse of epoch 10 for model mlp_1 and data ml-1m is: 00: 00: 38\n",
      "HR: 0.592\tNDCG: 0.330\n",
      "The time elapse of epoch 5 for model mlp_2 and data ml-1m is: 00: 00: 44\n",
      "HR: 0.605\tNDCG: 0.344\n",
      "The time elapse of epoch 10 for model mlp_2 and data ml-1m is: 00: 00: 44\n",
      "HR: 0.627\tNDCG: 0.363\n",
      "The time elapse of epoch 5 for model mlp_3 and data ml-1m is: 00: 00: 46\n",
      "HR: 0.633\tNDCG: 0.365\n",
      "The time elapse of epoch 10 for model mlp_3 and data ml-1m is: 00: 00: 49\n",
      "HR: 0.652\tNDCG: 0.378\n",
      "The time elapse of epoch 5 for model mlp_4 and data ml-1m is: 00: 00: 52\n",
      "HR: 0.650\tNDCG: 0.378\n",
      "The time elapse of epoch 10 for model mlp_4 and data ml-1m is: 00: 00: 48\n",
      "HR: 0.665\tNDCG: 0.387\n",
      "The time elapse of epoch 5 for model mlp_0 and data pinterest-20 is: 00: 01: 11\n",
      "HR: 0.274\tNDCG: 0.141\n",
      "The time elapse of epoch 10 for model mlp_0 and data pinterest-20 is: 00: 01: 10\n",
      "HR: 0.274\tNDCG: 0.141\n",
      "The time elapse of epoch 5 for model mlp_1 and data pinterest-20 is: 00: 01: 17\n",
      "HR: 0.810\tNDCG: 0.486\n",
      "The time elapse of epoch 10 for model mlp_1 and data pinterest-20 is: 00: 01: 15\n",
      "HR: 0.828\tNDCG: 0.503\n",
      "The time elapse of epoch 5 for model mlp_2 and data pinterest-20 is: 00: 01: 26\n",
      "HR: 0.827\tNDCG: 0.502\n",
      "The time elapse of epoch 10 for model mlp_2 and data pinterest-20 is: 00: 01: 25\n",
      "HR: 0.834\tNDCG: 0.508\n",
      "The time elapse of epoch 5 for model mlp_3 and data pinterest-20 is: 00: 01: 36\n",
      "HR: 0.842\tNDCG: 0.512\n",
      "The time elapse of epoch 10 for model mlp_3 and data pinterest-20 is: 00: 01: 30\n",
      "HR: 0.842\tNDCG: 0.513\n",
      "The time elapse of epoch 5 for model mlp_4 and data pinterest-20 is: 00: 01: 35\n",
      "HR: 0.848\tNDCG: 0.516\n",
      "The time elapse of epoch 10 for model mlp_4 and data pinterest-20 is: 00: 01: 39\n",
      "HR: 0.846\tNDCG: 0.517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for data_name in ['ml-1m','pinterest-20']:\n",
    "    MLP_layers(data_name, NUM_EPOCHS, 'adam', lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6e4dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e14f03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21841e7e",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f4599e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>HR</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>data_name</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.453477</td>\n",
       "      <td>0.252633</td>\n",
       "      <td>ml-1m</td>\n",
       "      <td>mlp_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>0.591722</td>\n",
       "      <td>0.330141</td>\n",
       "      <td>ml-1m</td>\n",
       "      <td>mlp_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10</td>\n",
       "      <td>0.627483</td>\n",
       "      <td>0.362892</td>\n",
       "      <td>ml-1m</td>\n",
       "      <td>mlp_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10</td>\n",
       "      <td>0.652483</td>\n",
       "      <td>0.377942</td>\n",
       "      <td>ml-1m</td>\n",
       "      <td>mlp_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>10</td>\n",
       "      <td>0.664735</td>\n",
       "      <td>0.386886</td>\n",
       "      <td>ml-1m</td>\n",
       "      <td>mlp_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>10</td>\n",
       "      <td>0.274412</td>\n",
       "      <td>0.140705</td>\n",
       "      <td>pinterest-20</td>\n",
       "      <td>mlp_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>10</td>\n",
       "      <td>0.828130</td>\n",
       "      <td>0.502906</td>\n",
       "      <td>pinterest-20</td>\n",
       "      <td>mlp_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>10</td>\n",
       "      <td>0.833928</td>\n",
       "      <td>0.508390</td>\n",
       "      <td>pinterest-20</td>\n",
       "      <td>mlp_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>10</td>\n",
       "      <td>0.841829</td>\n",
       "      <td>0.512778</td>\n",
       "      <td>pinterest-20</td>\n",
       "      <td>mlp_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>10</td>\n",
       "      <td>0.845580</td>\n",
       "      <td>0.516950</td>\n",
       "      <td>pinterest-20</td>\n",
       "      <td>mlp_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch        HR      NDCG     data_name model_name\n",
       "9      10  0.453477  0.252633         ml-1m      mlp_0\n",
       "19     10  0.591722  0.330141         ml-1m      mlp_1\n",
       "29     10  0.627483  0.362892         ml-1m      mlp_2\n",
       "39     10  0.652483  0.377942         ml-1m      mlp_3\n",
       "49     10  0.664735  0.386886         ml-1m      mlp_4\n",
       "59     10  0.274412  0.140705  pinterest-20      mlp_0\n",
       "69     10  0.828130  0.502906  pinterest-20      mlp_1\n",
       "79     10  0.833928  0.508390  pinterest-20      mlp_2\n",
       "89     10  0.841829  0.512778  pinterest-20      mlp_3\n",
       "99     10  0.845580  0.516950  pinterest-20      mlp_4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlp = pd.read_csv('./Output/mlp.csv')\n",
    "df_mlp[df_mlp['epoch']==10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c48a6aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01ae55ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>HR</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>data_name</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.636093</td>\n",
       "      <td>0.363548</td>\n",
       "      <td>ml-1m</td>\n",
       "      <td>gmf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>0.661921</td>\n",
       "      <td>0.385522</td>\n",
       "      <td>ml-1m</td>\n",
       "      <td>neumf_pre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10</td>\n",
       "      <td>0.847537</td>\n",
       "      <td>0.520955</td>\n",
       "      <td>pinterest-20</td>\n",
       "      <td>gmf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10</td>\n",
       "      <td>0.860927</td>\n",
       "      <td>0.534515</td>\n",
       "      <td>pinterest-20</td>\n",
       "      <td>neumf_pre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch        HR      NDCG     data_name model_name\n",
       "9      10  0.636093  0.363548         ml-1m        gmf\n",
       "19     10  0.661921  0.385522         ml-1m  neumf_pre\n",
       "29     10  0.847537  0.520955  pinterest-20        gmf\n",
       "39     10  0.860927  0.534515  pinterest-20  neumf_pre"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ncf = pd.read_csv('./Output/ncf.csv')\n",
    "df_ncf[df_ncf['epoch']==10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9e45ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db219f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50535e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547fae78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255536f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
