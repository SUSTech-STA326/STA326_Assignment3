{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505ac971",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP lr = 0.0001 layers = [64,32,16,8] - HR: 0.462\n",
    "MLP lr = 0.0001 layers = [128,64,32,16] - HR: 0.467\n",
    "MLP lr = 0.0001 layers = [256, 128, 64, 32] - HR: 0.446\n",
    "MLP lr = 0.0001 layers = [512, 256, 128, 64] - HR: 0.400\n",
    "MLP lr = 0.0001 layers = [256, 128, 64] - HR: 0.428\n",
    "MLP lr = 0.0001 layers = [128, 64, 32] - HR: 0.456\n",
    "MLP lr = 0.0001 layers = [64, 32, 16] - HR: 0.467\n",
    "MLP lr = 0.0001 layers = [32, 16, 8] - HR: 0.469\n",
    "MLP lr = 0.0001 layers = [16, 8] - HR: 0.461\n",
    "MLP lr = 0.0001 layers = [32, 16] - HR: 0.468\n",
    "MLP lr = 0.0001 layers = [64, 32] - HR: 0.467\n",
    "MLP lr = 0.0001 layers = [128, 64] - HR: 0.464\n",
    "MLP lr = 0.0001 layers = [64] - HR: 0.463\n",
    "MLP lr = 0.0001 layers = [32] - HR: 0.467\n",
    "MLP lr = 0.0001 layers = [16] - HR: 0.470\n",
    "MLP lr = 0.0001 layers = [8] - HR: 0.454"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a1525e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371ba9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_list = [128, 256, 512, 1024]\n",
    "lr_list = [0.0001 ,0.0005, 0.001, 0.005]\n",
    "factors = [8, 16, 32, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdc5e35b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 7 (450998936.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    embedding_dim = factors\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 7\n"
     ]
    }
   ],
   "source": [
    "for batch_size in batch_size_list:\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    validation_loader = DataLoader(validation_dataset, batch_size=64, shuffle=True, num_workers=1)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=101, shuffle=True, num_workers=1)\n",
    "    \n",
    "    for lr in lr_list:\n",
    "        for factor in factors:\n",
    "    \n",
    "        embedding_dim = factors\n",
    "        lr = lr\n",
    "        loss_function = nn.BCEWithLogitsLoss() # 定义损失函数\n",
    "        \n",
    "        GMF_model = GMF(UserID_num+1, MovieID_num+1, embedding_dim)\n",
    "        \n",
    "        layers =  [factor*(2**i) for i in reversed(range(4))] # range里面的数代表几层隐藏层，4代表3层\n",
    "        reg_layers = [0] * 4\n",
    "        droupout = [0] * 4\n",
    "        MLP_model = MLP(UserID_num+1, MovieID_num+1, layers, reg_layers, droupout)\n",
    "        \n",
    "        optimizer = optim.Adam(GMF_model.parameters(), lr=lr) # 定义优化器\n",
    "        optimizer = optim.Adam(MLP_model.parameters(), lr=lr) # 定义优化器\n",
    "        \n",
    "        print(\"本次训练batch_size为：\", batch_size, \"lr为：\", lr, \"factor为：\", factor, \"开始训练GMF_model\")\n",
    "        training_model(GMF_model, train_loader, test_loader, 20, 10) \n",
    "        print(\"本次训练batch_size为：\", batch_size, \"lr为：\", lr, \"factor为：\", factor, \"开始训练MLP_model\")\n",
    "        training_model(MLP_model, train_loader, test_loader, 20, 10) \n",
    "        \n",
    "        ############################## NeuMF_model ####################################\n",
    "        gmf_embedding_dim = factors\n",
    "        mlp_layers = layers\n",
    "        reg_layers = reg_layers\n",
    "        dropout = droupout\n",
    "        # 创建NeuMF模型并加载预训练参数\n",
    "        NeuMF_model = NeuMF(UserID_num+1, MovieID_num+1, gmf_embedding_dim, mlp_layers, reg_layers, dropout, alpha=0.5)\n",
    "        NeuMF_model.load_pretrained_weights(GMF_model, MLP_model)\n",
    "        # 使用SGD优化器训练NeuMF\n",
    "        lr = lr\n",
    "        optimizer = optim.SGD(NeuMF_model.parameters(), lr=lr)\n",
    "        loss_function = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        print(\"本次训练batch_size为：\", batch_size, \"lr为：\", lr, \"factor为：\", factor, \"开始训练NeuMF_model\")\n",
    "        training_model(NeuMF_model, train_loader, test_loader, 20, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14dd8328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 1, 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in reversed(range(4))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251343c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6854cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcbdab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b1a4879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# 定义CSV文件的文件名\n",
    "GMF_csv_filename = 'outcome/GMF.csv'\n",
    "MLP_csv_filename = 'outcome/MLP.csv'\n",
    "NeuMF_csv_filename = 'outcome/NeuMF.csv'\n",
    "\n",
    "csv_filename_list = [GMF_csv_filename, MLP_csv_filename, NeuMF_csv_filename]\n",
    "\n",
    "# 创建并初始化CSV文件，写入表头\n",
    "for csv_filename in csv_filename_list:\n",
    "    with open(csv_filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # 写入表头\n",
    "        writer.writerow(['batch_size', 'lr', 'factor', \"HR\", \"NDCG\"])\n",
    "\n",
    "# 函数：逐行添加数据到CSV文件\n",
    "def append_to_csv(csv_filename, batch_size, lr, factor, HR, NDCG):\n",
    "    with open(csv_filename, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # 写入一行数据\n",
    "        writer.writerow([batch_size, lr, factor, HR, NDCG])\n",
    "\n",
    "# 示例：逐行添加数据\n",
    "append_to_csv(GMF_csv_filename, 1, 11, 1, 101, 5)\n",
    "# append_to_csv(2, 102, 4)\n",
    "# append_to_csv(3, 103, 3)\n",
    "\n",
    "# print(f\"数据已成功添加到 {csv_filename} 文件中。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
