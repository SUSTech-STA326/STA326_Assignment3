{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tensorboardX import SummaryWriter\n",
    "# from utils import save_checkpoint, use_optimizer\n",
    "# from metrics import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(MLP, self).__init__()\n",
    "        self.config = config\n",
    "        self.num_users = config['num_users']\n",
    "        self.num_items = config['num_items']\n",
    "        self.latent_dim = config['latent_dim_mlp']\n",
    "\n",
    "        self.embedding_user = torch.nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.latent_dim)\n",
    "        self.embedding_item = torch.nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.latent_dim)\n",
    "\n",
    "        self.fc_layers = torch.nn.ModuleList()\n",
    "        for idx, (in_size, out_size) in enumerate(zip(config['layers'][:-1], config['layers'][1:])):\n",
    "            self.fc_layers.append(torch.nn.Linear(in_size, out_size))\n",
    "\n",
    "        self.affine_output = torch.nn.Linear(in_features=config['layer'][-1], out_features=1)\n",
    "        self.logistic = torch.nn.Sigmoid()\n",
    "\n",
    "        if config['weight_init_gaussian']:\n",
    "            for sm in self.modules():\n",
    "                if isinstance(sm, (nn.Embedding, nn.Linear)):\n",
    "                    torch.nn.init.normal_(sm.weight.data, 0.0, 0.01)\n",
    "        \n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embedding = self.embedding_user(user_indices)\n",
    "        item_embedding = self.embedding_item(item_indices)\n",
    "        x = torch.cat([user_embedding, item_embedding], dim=-1)\n",
    "        for idx, _ in enumerate(len(self.fc_layers)):\n",
    "            x = self.fc_layers[idx](x)\n",
    "            x = torch.nn.ReLU()(x)\n",
    "        logits = self.affine_output(x)\n",
    "        rating = self.logistic(logits)\n",
    "        return rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [16]\n",
    "for idx in enumerate(range(0)):\n",
    "    print('hi')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "class Metrics:\n",
    "    def __init__(self, top_k):\n",
    "        self._top_k = top_k\n",
    "        self._subjects = None\n",
    "    \n",
    "    @property\n",
    "    def subjects(self):\n",
    "        return self._subjects\n",
    "    \n",
    "    @subjects.setter\n",
    "    def subjects(self, subjects):\n",
    "        test_users, test_items, test_scores ,neg_users, neg_items, neg_scores = \\\n",
    "            subjects[0], subjects[1], subjects[2],subjects[3], subjects[4], subjects[5]\n",
    "\n",
    "        # the golden set\n",
    "        test = pd.DataFrame({\n",
    "            'user': test_users,\n",
    "            'test_item': test_items,\n",
    "            'test_score': test_scores\n",
    "        })\n",
    "\n",
    "        full = pd.DataFrame({\n",
    "            'user': neg_users + test_users,\n",
    "            'item': neg_items + test_items,\n",
    "            'score': neg_scores + test_scores\n",
    "        })\n",
    "\n",
    "        full = pd.merge(full, test, on=['user'], how='left')\n",
    "\n",
    "        full['rank'] = full.groupBy('user')['score'].rank(method='first', ascending=False)\n",
    "        full.sort_values(['user', 'rank'], inplace=True)\n",
    "        self._subjects = full\n",
    "        \n",
    "        \n",
    "    def cal_hit_ratio(self):\n",
    "        full, top_k = self._subjects, self._top_k\n",
    "        top_k = full[full['rank'] <= top_k]\n",
    "        test_in_top_k = top_k[top_k['test_item'] == top_k['item']]\n",
    "        return len(test_in_top_k) * 1.0 / full['user'].nunique()\n",
    "    \n",
    "    def cal_ndcg(self):\n",
    "        full, top_k = self._subjects, self._top_k\n",
    "        top_k = full[full['rank'] <= top_k]\n",
    "        test_in_top_k = top_k[top_k['test_item'] == top_k['item']]\n",
    "        test_in_top_k['ndcg'] = test_in_top_k['rank'].apply(lambda x: math.log(2) / math.log(1 + x))\n",
    "        return test_in_top_k['ndcg'].sum() * 1.0 / full['user'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, config, generator, evaluator):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model = model.to(self.device)\n",
    "        self.config = config\n",
    "        self.generator = generator\n",
    "        self.evaluator = evaluator\n",
    "        self.evaluate_data = self.generator.evaluate_data\n",
    "        self.optimizer = self.get_optimizer()\n",
    "        self.crit = torch.nn.BCELoss()\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        if self.config['optimizer'] == 'sgd':\n",
    "            optimizer = torch.optim.SGD(self.model.parameters(),\n",
    "                                        lr=self.config['sgd']['lr'],\n",
    "                                        momentum=self.config['sgd']['momentum'],\n",
    "                                        weight_decay=self.config['sgd']['l2_regularization'])\n",
    "        elif self.config['optimizer'] == 'adam':\n",
    "            optimizer = torch.optim.Adam(self.model.parameters(),\n",
    "                                        lr=self.config['adam']['lr'],\n",
    "                                        weight_decay=self.config['adam']['l2_regularization'])\n",
    "        elif self.config['optimizer'] == 'rmsprop':\n",
    "            optimizer = torch.optim.RMSprop(self.model.parameters(),\n",
    "                                            lr=self.config['rmsprop']['lr'],\n",
    "                                            alpha=self.config['rmsprop']['alpha'],\n",
    "                                            momentum=self.config['rmsprop']['momentum'])\n",
    "        return optimizer\n",
    "\n",
    "    def _train_batch(self, users, items, ratings):\n",
    "        if self.config['use_cuda']:\n",
    "            users, items, ratings = users.to(self.device), items.to(self.device), ratings.to(self.device)\n",
    "        self.optimizer.zero_grad()\n",
    "        ratings_pred = self.model(users, items)\n",
    "        loss = self.crit(ratings_pred.view(-1), ratings)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        loss = loss.item()\n",
    "        return loss\n",
    "\n",
    "    def _train_epoch(self, train_loader, epoch_id):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        for _, batch in enumerate(train_loader):\n",
    "            user, item, rating = batch[0], batch[1], batch[2]\n",
    "            rating = rating.float()\n",
    "            loss = self._train_batch(user, item, rating)\n",
    "            total_loss += loss\n",
    "        return total_loss\n",
    "    \n",
    "    def evaluate_epoch(self):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_users, test_items, negative_users, negative_items = \\\n",
    "                  self.evaluate_data[0], self.evaluate_data[1], self.evaluate_data[2], self.evaluate_data[3]\n",
    "            if self.config['use_cuda']:\n",
    "                test_users, test_items, negative_users, negative_items = \\\n",
    "                    test_users.to(self.device), test_items.to(self.device), negative_users.to(self.device), negative_items.to(self.device)                                                                                                                            \n",
    "            test_scores = self.model(test_users, test_items).cpu()\n",
    "            negative_scores = self.model(negative_users, negative_items).cpu()\n",
    "            test_users, test_items, negative_users, negative_items = \\\n",
    "                test_users.cpu(), test_items.cpu(), negative_users.cpu(), negative_items.cpu()\n",
    "            self.evaluator.subjects = [\n",
    "                test_users.detach().view(-1).tolist(),\n",
    "                test_items.detach().view(-1).tolist(),\n",
    "                test_scores.detach().view(-1).tolist(),\n",
    "                negative_users.detach().view(-1).tolist(),\n",
    "                negative_items.detach().view(-1).tolist(),\n",
    "                negative_scores.detach().view(-1).tolist\n",
    "            ]\n",
    "        hit_ratio, ndcg = self.evaluator.cal_hit_ratio(), self.evaluator.cal_ndcg()\n",
    "        return hit_ratio, ndcg\n",
    "     \n",
    "    def save(self, epoch_id, hit_ratio, ndcg):\n",
    "        model_dir = self.config['model_dir'].format(self.config['alias'], epoch_id, hit_ratio, ndcg)\n",
    "        torch.save(self.model.state_dict(), model_dir)\n",
    "    \n",
    "    def train(self):\n",
    "        for epoch in range(self.config['num_epoch']):\n",
    "            print('Epoch {} starts !'.format(epoch))\n",
    "            print('-' * 80)\n",
    "            train_loader = self.generator.get_train_loader(self.config['num_negative'], self.config['batch_size'])\n",
    "            loss = self._train_epoch(train_loader, epoch_id=epoch)\n",
    "            print('[Training Epoch {}] Batch {}, Loss {}'.format(epoch, loss))\n",
    "            hit_ratio, ndcg = self.evaluate_epoch(epoch_id=epoch)\n",
    "            self.save(epoch, hit_ratio, ndcg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64, 32, 16, 8]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = [16, 64, 32, 16, 8]\n",
    "layer[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(16, 64)\n",
      "1\n",
      "(64, 32)\n",
      "2\n",
      "(32, 16)\n",
      "3\n",
      "(16, 8)\n"
     ]
    }
   ],
   "source": [
    "for i, j in enumerate(zip(layer[:-1], layer[1:])):\n",
    "    print(i)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_config = {\n",
    "            'alias': 'mlp_factor8neg4_bz256_166432168_pretrain_reg_0.0000001',\n",
    "            'num_epoch': 200,\n",
    "            'batch_size': 256,  # 1024,\n",
    "            'optimizer': {              \n",
    "                'type': 'adam',\n",
    "                'params': {\n",
    "                    'lr' : 1e-3,\n",
    "                    'l2_regularizarion': 0.0000001 # MLP model is sensitive to hyper params\n",
    "                }\n",
    "            },      \n",
    "            'num_users': 6040,\n",
    "            'num_items': 3706,\n",
    "            'latent_dim': 8,\n",
    "            'num_negative': 4,\n",
    "            'layers': [16, 64, 32, 16, 8],  # layers[0] is the concat of latent user vector & latent item vector\n",
    "            'weight_init_gaussian': True,\n",
    "            'use_cuda': True,\n",
    "            'device_id': 0,\n",
    "            'pretrain': False,\n",
    "            'pretrain_mf': 'checkpoints/{}'.format('gmf_factor8neg4_Epoch100_HR0.6391_NDCG0.2852.model'),\n",
    "            'model_dir': 'checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model'\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_config['optimizer']['params']['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
